
# Final project report: Pipeline de Big Data do ENEM com Spark e Docker Swarm

## 1. Context and motivation

O principal objetivo deste projeto √© processar e analisar grandes volumes de dados educacionais, especificamente os microdados do ENEM, utilizando tecnologias de Big Data. Buscamos resolver o problema de an√°lise eficiente de dados massivos (13+ milh√µes de registros anuais) para extrair insights sobre desigualdade educacional no Brasil.

O foco est√° na constru√ß√£o de um pipeline escal√°vel e distribu√≠do que possa:
- Processar automaticamente m√∫ltiplos anos de dados do ENEM (2020, 2021, 2023)
- Realizar an√°lises estat√≠sticas complexas sobre correla√ß√µes socioecon√¥micas
- Demonstrar a viabilidade de infraestrutura containerizada para Big Data
- Responder perguntas importantes sobre disparidades regionais e socioecon√¥micas na educa√ß√£o brasileira

A motiva√ß√£o √© demonstrar como tecnologias modernas de Big Data podem ser aplicadas para gerar evid√™ncias que subsidiem pol√≠ticas p√∫blicas educacionais baseadas em dados.

## 2. Data

### 2.1 Detailed description

**Fonte dos dados:**
- **Instituto Nacional de Estudos e Pesquisas Educacionais An√≠sio Teixeira (INEP)**
- Link oficial: https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados

**Conte√∫do dos dados:**
- Microdados do ENEM dos anos de 2020, 2021 e 2023
- **Volume total**: Aproximadamente 13+ milh√µes de registros distribu√≠dos em:
  - ENEM 2020: ~5 milh√µes de candidatos
  - ENEM 2021: ~3 milh√µes de candidatos  
  - ENEM 2023: ~3+ milh√µes de candidatos
- **Caracter√≠sticas por registro**:
  - Centenas de atributos por candidato
  - Informa√ß√µes socioecon√¥micas detalhadas (renda familiar, escolaridade dos pais, etc.)
  - Localiza√ß√£o geogr√°fica (estado onde realizou a prova)
  - Notas por √°rea de conhecimento (Ci√™ncias da Natureza, Ci√™ncias Humanas, Linguagens e C√≥digos, Matem√°tica)
  - Tipo de escola (p√∫blica/privada)
  - Dados demogr√°ficos

**Formato dos dados:**
- Arquivos CSV delimitados por ponto e v√≠rgula (;)
- Codifica√ß√£o ISO-8859-1
- Compactados em arquivos ZIP (~500MB-1.5GB cada arquivo)
- Tamanho total descompactado: ~15GB

### 2.2 How to obtain the data

**Amostra de dados (obrigat√≥ria):**
Uma pequena amostra dos dados est√° inclu√≠da na pasta `datasample/enem_sample.csv` deste reposit√≥rio. Esta amostra cont√©m 15 registros representativos (tamanho < 1KB) e √© obrigat√≥ria para permitir testes r√°pidos do projeto.

**Dataset completo:**
Para obter o dataset completo (n√£o inclu√≠do no reposit√≥rio), use os comandos abaixo:

```bash
# Download autom√°tico via wget
wget https://download.inep.gov.br/microdados/microdados_enem_2020.zip
wget https://download.inep.gov.br/microdados/microdados_enem_2021.zip
wget https://download.inep.gov.br/microdados/microdados_enem_2023.zip
```

**Observa√ß√£o importante:** O pipeline realiza download autom√°tico dos dados durante a execu√ß√£o. N√£o √© necess√°rio baixar manualmente os arquivos, exceto se desejar pr√©-carregar os dados. Se os arquivos ZIP estiverem presentes na raiz do projeto, o pipeline os utilizar√° automaticamente.

## 3. How to install and run

> Observa√ß√£o: O projeto √© totalmente compat√≠vel com uma instala√ß√£o padr√£o do Docker e usa apenas cont√™ineres Docker para execu√ß√£o. Nenhuma ferramenta externa ou instala√ß√£o adicional √© necess√°ria ‚Äî este √© um requisito estrito.

### 3.1 Quick start (usando dados de amostra em `datasample/`)

Execute o projeto imediatamente usando Docker com os comandos exatos abaixo:

**Linux/macOS:**
```bash
# Tornar scripts execut√°veis
chmod +x bin/*.sh

# Executar pipeline completo
./bin/run.sh
```

**Windows:**
```cmd
# Executar pipeline completo
bin\run.bat
```

**Alternativa manual usando Docker Compose:**
```bash
# Construir imagem Docker
docker build -t enem-spark-job -f misc/Dockerfile .

# Executar com Docker Compose
cd misc
docker-compose up --scale spark-worker=2 --scale datanode=1 -d
```

### 3.2 Como executar com o dataset completo

Para usar o dataset completo (em vez da amostra padr√£o):

1. **Op√ß√£o 1 (Autom√°tica)**: Execute normalmente. O pipeline baixar√° automaticamente os dados do INEP.

2. **Op√ß√£o 2 (Manual)**: Baixe os arquivos ZIP e coloque na raiz do projeto:
   ```bash
   wget https://download.inep.gov.br/microdados/microdados_enem_2020.zip
   wget https://download.inep.gov.br/microdados/microdados_enem_2021.zip
   wget https://download.inep.gov.br/microdados/microdados_enem_2023.zip
   ```

O pipeline detectar√° automaticamente os arquivos presentes e os utilizar√°.

## 4. Project architecture

O sistema possui uma arquitetura distribu√≠da baseada em cont√™ineres Docker que implementa um pipeline completo de Big Data:

```
[Dados INEP (ZIP)] 
       ‚Üì
[Download/Extra√ß√£o Autom√°tica]
       ‚Üì
[HDFS] ‚Üê‚Üí [Cluster Spark (PySpark)]
       ‚Üì
[Resultados em HDFS: Parquet + M√©tricas]
```

### Principais componentes e intera√ß√µes:

**1. Camada de Dados:**
- **Fonte**: Arquivos ZIP dos microdados ENEM do INEP
- **Ingest√£o**: Download e extra√ß√£o autom√°tica pelo container spark-job
- **Armazenamento**: HDFS distribu√≠do (namenode + datanodes)

**2. Camada de Processamento:**
- **spark-master**: Coordenador do cluster Spark
- **spark-worker[n]**: N√≥s de processamento distribu√≠do (escal√°veis)
- **spark-job**: Container da aplica√ß√£o PySpark principal

**3. Camada de Armazenamento:**
- **namenode**: Servidor de metadados do HDFS
- **datanode[n]**: N√≥s de armazenamento distribu√≠do (escal√°veis)

**4. Fluxo de dados:**
1. Container `spark-job` baixa dados do INEP
2. Dados s√£o extra√≠dos e carregados no HDFS
3. Spark processa dados distribu√≠dos atrav√©s dos workers
4. Resultados anal√≠ticos s√£o salvos em formato Parquet no HDFS
5. M√©tricas de performance s√£o coletadas em tempo real

**Execu√ß√£o em cont√™ineres:**
- Todos os componentes executam em cont√™ineres Docker isolados
- Comunica√ß√£o via rede interna `hadoop`
- Volume compartilhado `./data` para persist√™ncia local
- Escalabilidade horizontal via Docker Compose scaling

**Interfaces de monitoramento:**
- **Spark Master UI**: http://localhost:8080 (monitoramento do cluster)
- **HDFS NameNode UI**: http://localhost:9870 (sistema de arquivos)

## 5. Workloads evaluated

Este projeto avalia tr√™s principais cargas de trabalho no contexto de processamento de Big Data:

**[WORKLOAD-1] Ingest√£o de Dados:**
- **Descri√ß√£o**: Download, extra√ß√£o e carregamento de arquivos CSV massivos (>500MB cada) para o HDFS
- **Opera√ß√µes espec√≠ficas**:
  - Download autom√°tico de arquivos ZIP do INEP via HTTPS
  - Extra√ß√£o de arquivos comprimidos (descompress√£o)
  - Transfer√™ncia para HDFS usando API Hadoop
  - Cria√ß√£o de estrutura hier√°rquica de diret√≥rios
- **M√©tricas avaliadas**: Tempo de download, throughput de transfer√™ncia, utiliza√ß√£o de rede

**[WORKLOAD-2] Transforma√ß√£o e Enriquecimento de Dados:**
- **Descri√ß√£o**: Limpeza, normaliza√ß√£o e engenharia de features em milh√µes de registros
- **Opera√ß√µes espec√≠ficas**:
  - Normaliza√ß√£o de colunas num√©ricas (remo√ß√£o de caracteres especiais)
  - Mapeamento de c√≥digos categ√≥ricos para valores num√©ricos (renda familiar)
  - Filtragem de registros inv√°lidos e duplicados
  - Cria√ß√£o de features derivadas (regi√µes geogr√°ficas)
  - Reparticionamento otimizado para paralelismo
- **M√©tricas avaliadas**: Registros processados por segundo, utiliza√ß√£o de CPU/mem√≥ria

**[WORKLOAD-3] An√°lises Estat√≠sticas Complexas:**
- **Descri√ß√£o**: Agrega√ß√µes complexas, correla√ß√µes e consultas anal√≠ticas multi-anuais
- **Opera√ß√µes espec√≠ficas**:
  - C√°lculos de m√©dias por agrupamentos (UF, tipo de escola, regi√£o)
  - Correla√ß√µes de Pearson entre vari√°veis num√©ricas
  - An√°lises de desvio padr√£o e dispers√£o
  - Opera√ß√µes de join entre datasets de diferentes anos
  - Cria√ß√£o de faixas categ√≥ricas e an√°lises de distribui√ß√£o
- **M√©tricas avaliadas**: Tempo de execu√ß√£o de queries, throughput anal√≠tico, efici√™ncia de agrega√ß√µes

## 6. Experiments and results

## 6. Experiments and results

### 6.1 Experimental environment

Os experimentos foram executados em um ambiente com as seguintes especifica√ß√µes:

**Configura√ß√£o de Hardware:**
- **CPU**: 6 cores f√≠sicos, 12 processadores l√≥gicos
- **RAM**: 16 GB DDR4
- **Armazenamento**: SSD NVMe
- **OS**: Ambiente de cont√™ineres Linux via Docker no Windows

**Stack de Software:**
- **Apache Spark**: 3.x (distribui√ß√£o Bitnami)
- **Hadoop HDFS**: 3.2.1
- **Python**: 3.8+
- **Docker**: Vers√£o est√°vel mais recente
- **Docker Compose**: v2.x

### 6.2 What did you test?

Realizamos testes abrangentes de performance variando diferentes configura√ß√µes de infraestrutura:

**Par√¢metros testados:**
1. **Escalabilidade computacional**: N√∫mero de Spark workers (1, 2, 3+)
2. **Escalabilidade de armazenamento**: N√∫mero de HDFS datanodes (1, 2)
3. **Aloca√ß√£o de recursos**: Mem√≥ria e CPU por worker

**M√©tricas coletadas:**
- **Tempo de execu√ß√£o**: Tempo total end-to-end (wall-clock time)
- **Throughput**: Registros processados por segundo
- **Utiliza√ß√£o de recursos**: CPU e mem√≥ria por worker
- **Lat√™ncia**: Tempo de resposta para opera√ß√µes individuais
- **M√©tricas de aplica√ß√£o**: N√∫mero de parti√ß√µes, shuffle operations

**Configura√ß√µes testadas:**
- **Baseline**: 1 Worker + 1 DataNode
- **Escala computacional**: 2 Workers + 1 DataNode  
- **Escala storage**: 2 Workers + 2 DataNodes
- **Limita√ß√£o de recursos**: 3+ Workers (limitado por RAM dispon√≠vel)

**Replica√ß√µes**: Cada configura√ß√£o foi executada uma vez com dataset completo devido ao tempo de execu√ß√£o (~6-7 horas por experimento). O pipeline coleta m√©tricas cont√≠nuas durante a execu√ß√£o para garantir consist√™ncia.

### 6.3 Results

#### Tabela de Performance por Configura√ß√£o

| Configura√ß√£o | Tempo (s) | Registros   | Throughput (reg/s) | CPU Total (%) | RAM M√©dia (MB) | Threads/Worker |
|--------------|-----------|-------------|-------------------|---------------|----------------|----------------|
| 1W / 1D      | 415,66    | 7.535.711   | 18.129,37         | 50,0%         | 4.096          | 3,0            |
| 2W / 1D      | 362,80    | 7.535.711   | 20.770,75         | 50,0%         | 4.096          | 3,0            |
| 2W / 2D      | 365,82    | 7.535.711   | 20.599,35         | 50,0%         | 4.096          | 3,0            |

A partir de 3 workers tivemos problema de RAM para a execu√ß√£o do Job

**An√°lise dos resultados de performance:**

1. **Melhor configura√ß√£o**: 2 Workers + 1 DataNode apresentou o melhor desempenho
2. **Ganho de throughput**: ~14% de melhoria ao escalar de 1 para 2 workers  
3. **Limita√ß√£o de recursos**: Mem√≥ria se torna fator limitante al√©m de 2 workers
4. **Escalabilidade de storage**: DataNodes adicionais mostram impacto m√≠nimo na performance

**O que aprendemos:**
- A configura√ß√£o √≥tima para nosso ambiente √© 2W/1D
- O gargalo principal √© mem√≥ria, n√£o CPU ou armazenamento
- O paralelismo horizontal √© efetivo at√© o limite de recursos
- HDFS scaling tem retornos decrescentes para este workload

#### Resultados Anal√≠ticos dos Dados ENEM

O pipeline processou com sucesso 7,5+ milh√µes de registros do ENEM, gerando insights educacionais abrangentes:

**üìä 1. Performance Acad√™mica por Estado (Amostra 2020):**
- S√£o Paulo (SP): 541,20 pontos (maior m√©dia)
- Minas Gerais (MG): 534,08 pontos  
- Acre (AC): 480,82 pontos
- Amap√° (AP): 476,80 pontos (menor m√©dia)

*Diferen√ßa de 64,4 pontos entre estados extremos revela disparidades significativas.*

**üè´ 2. Performance por Tipo de Escola (2020):**
| Tipo | Descri√ß√£o    | M√©dia ENEM |
|------|-------------|------------|
| 2    | P√∫blica     | 499,52     |
| 3    | Privada     | 610,63     |

*Vantagem de 111 pontos para escolas privadas demonstra desigualdade no sistema educacional.*

**üí∞ 3. Correla√ß√£o Renda vs Matem√°tica:**
| Ano  | Correla√ß√£o Pearson |
|------|--------------------|
| 2020 | 0,3945             |
| 2021 | 0,3745             |
| 2023 | 0,3824             |

*Correla√ß√£o positiva consistente (~0,38) confirma impacto da renda no desempenho.*

**üåé 4. Desigualdade Regional:**
| Regi√£o      | M√©dia  | Desvio | Estudantes |
|-------------|--------|--------|------------|
| Sudeste     | 559,36 | 123,15 | 2.531.820  |
| Norte       | 487,11 | 103,82 | 818.062    |

*Diferen√ßa de 72 pontos entre regi√µes extremas evidencia desigualdade geogr√°fica.*

## 7. Discussion and conclusions

### O que funcionou bem:

**‚úÖ Implementa√ß√£o t√©cnica bem-sucedida:**
- Pipeline robusto e escal√°vel processando 7,5+ milh√µes de registros
- Aquisi√ß√£o autom√°tica de dados de fontes externas
- Processamento distribu√≠do eficiente com Apache Spark e HDFS
- Tratamento abrangente de erros e mecanismos de recupera√ß√£o
- Coleta de m√©tricas de performance em tempo real
- Containeriza√ß√£o completa garantindo reprodutibilidade

**‚úÖ Insights educacionais relevantes:**
- Confirma√ß√£o quantitativa da correla√ß√£o entre fatores socioecon√¥micos e desempenho acad√™mico
- Evid√™ncias claras de desigualdades regionais e por tipo de escola
- Dados que podem subsidiar pol√≠ticas p√∫blicas educacionais

### Desafios e limita√ß√µes:

**‚ö†Ô∏è Desafios t√©cnicos encontrados:**
- Complexidades de configura√ß√£o e permiss√µes do HDFS em ambiente containerizado
- Limita√ß√µes de aloca√ß√£o de mem√≥ria restringindo escalabilidade horizontal
- Gargalos de I/O de rede durante transfer√™ncia de datasets grandes
- Problemas de timing de orquestra√ß√£o de cont√™ineres durante inicializa√ß√£o
- Depend√™ncia de conectividade de internet para download de dados

**‚ö†Ô∏è Limita√ß√µes do trabalho:**
- Ambiente de teste limitado a uma √∫nica m√°quina (n√£o cluster real)
- An√°lises focadas em correla√ß√µes b√°sicas (sem modelos preditivos avan√ßados)
- Testes de performance limitados devido ao tempo de execu√ß√£o

### Conclus√µes:

Este projeto demonstra com sucesso a viabilidade de infraestrutura containerizada de Big Data para an√°lises educacionais. O pipeline processa efetivamente dados do ENEM em larga escala, fornecendo insights valiosos sobre o cen√°rio educacional brasileiro.

**Principais contribui√ß√µes:**
1. **T√©cnica**: Prova de conceito de pipeline Big Data totalmente containerizado
2. **Anal√≠tica**: Quantifica√ß√£o de desigualdades educacionais brasileiras
3. **Metodol√≥gica**: Template reproduz√≠vel para an√°lises similares

A forte correla√ß√£o entre fatores socioecon√¥micos e desempenho acad√™mico revelada por nossa an√°lise refor√ßa a import√¢ncia de abordar a desigualdade educacional atrav√©s de interven√ß√µes pol√≠ticas baseadas em evid√™ncias.

## 8. References and external resources

**Fontes de dados:**
- [Microdados ENEM - INEP](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados) - Instituto Nacional de Estudos e Pesquisas Educacionais An√≠sio Teixeira

**Tecnologias e ferramentas:**
- [Apache Spark](https://spark.apache.org/) - Framework de processamento distribu√≠do
- [Apache Hadoop HDFS](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html) - Sistema de arquivos distribu√≠do
- [Docker](https://docs.docker.com/) - Plataforma de containeriza√ß√£o
- [Docker Compose](https://docs.docker.com/compose/) - Orquestra√ß√£o de multi-cont√™ineres

**Imagens Docker utilizadas:**
- [Bitnami Spark Docker](https://hub.docker.com/r/bitnami/spark) - Imagem base do Spark
- [BDE Hadoop Docker](https://github.com/big-data-europe/docker-hadoop) - Imagens do ecossistema Hadoop

**Bibliotecas Python:**
- [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) - API Python para Apache Spark
- [Requests](https://requests.readthedocs.io/) - Cliente HTTP para Python

**Documenta√ß√£o e tutoriais:**
- [Spark Programming Guide](https://spark.apache.org/docs/latest/programming-guide.html)
- [Docker Compose Reference](https://docs.docker.com/compose/compose-file/)
- [HDFS Commands Guide](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/CommandsManual.html)
